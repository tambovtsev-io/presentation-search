{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys, os\n",
    "sys.path.append(os.path.abspath(\"../../\"))\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.callbacks import tracing_v2_enabled\n",
    "from src.config import Config\n",
    "from src.rag import ChromaSlideStore\n",
    "import pandas as pd\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"default\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- [Измерение качества Retrieval](#toc1_)    \n",
    "  - [Измерение качества через разметку](#toc1_1_)    \n",
    "  - [RAGAS - оценка RAG без разметки](#toc1_2_)    \n",
    "    - [Входные данные](#toc1_2_1_)    \n",
    "    - [RAGAS для поиска презентаций](#toc1_2_2_)    \n",
    "- [Загрузка датасета с google.sheets](#toc2_)    \n",
    "- [Инициализация Retrieval](#toc3_)    \n",
    "- [Правила для оценки (evaluators)](#toc4_)    \n",
    "- [Запуск тестов](#toc5_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=false\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc1_'></a>[Измерение качества Retrieval](#toc0_)\n",
    "Для измерения качества я использую Langsmith.\n",
    "\n",
    "## <a id='toc1_1_'></a>[Измерение качества через разметку](#toc0_)\n",
    "В [таблице](https://docs.google.com/spreadsheets/d/1qWRF_o-RY1x-o-3z08iVb2akh0HS3ZNxVkZi6yoVsI4/edit?gid=0#gid=0) разменные презентации. Формат презентация-вопрос-слайды. Если в ответ выдали нужную презу, скор 1, иначе 0.\n",
    "\n",
    "## <a id='toc1_2_'></a>[RAGAS - оценка RAG без разметки](#toc0_)\n",
    "- [arxiv](http://arxiv.org/abs/2309.15217)\n",
    "- [Ноутбук с туториалом](https://colab.research.google.com/github/langfuse/langfuse-docs/blob/main/cookbook/evaluation_of_rag_with_ragas.ipynb)\n",
    "\n",
    "RAGAS - метод оценки генерации ответов RAG-системами.\n",
    "\n",
    "Идея: хотим оценивать ответы системы без разметки.\n",
    "\n",
    "Решение: придумаем метрики, которые 'self-contained and referece-free'.\n",
    "\n",
    "Что я не понял:\n",
    "- Почему Answer Relevance считается через эмбеддинги? Можно же гптшку спросить..\n",
    "- Зачем в Faithfulness разбиение на key-points? Опять же гптшка и без этого поймет\n",
    "\n",
    "\n",
    "### <a id='toc1_2_1_'></a>[Входные данные](#toc0_)\n",
    "В метриках RAGAS используются\n",
    "- Question - Исходный запрос\n",
    "- Answer - Ответ модели\n",
    "- Contexts - Документы, которые выдал Retrieval\n",
    "\n",
    "Метрики:\n",
    "- Faithfulness - ответ основывается на найденном контексте.\n",
    "- Answer Relevance - ответ соответствует вопросу.\n",
    "- Context Relevance - ответ модели строго по делу, без нерелевантной информации.\u0013\n",
    "\n",
    "### <a id='toc1_2_2_'></a>[RAGAS для поиска презентаций](#toc0_)\n",
    "В этом проекте ответом на запрос является слайды из конкретной презентации. У нас есть Contexts, но нет Answer. Метрики Faithfulness и Сontext Relevance отпадают сразу.\n",
    "\n",
    "Для метрики Answer Relevance можно попробовать Answer=`лучший слайд`. Идея метрики:\n",
    "- Для каждого ответа RAG-системы попросим LLM сгенерировать $n$ вопросов $q_i$.\n",
    "- Получим эмбеддинги этих вопросов $e_i$\n",
    "- Вычислим Similarity с эмбеддингом исходного запроса $e$: $AR = Mean(Sim(e, e_i))$\n",
    "\n",
    "Вот, что из этого вышло:\n",
    "LLM Генерила примерно одинаковые вопросы. Они были на английском, и не похожи на исходный. Получились рандомные скоры.\n",
    "\n",
    "Возможная причина: У них в примерах короткие вопросы и короткие ответы. LLM не знает что делать с большим описанием слайда. Примеры из их промпта:\n",
    "\n",
    "```\n",
    "--------EXAMPLES-----------\n",
    "Example 1\n",
    "Input: {\n",
    "    \"response\": \"Albert Einstein was born in Germany.\"\n",
    "}\n",
    "Output: {\n",
    "    \"question\": \"Where was Albert Einstein born?\",\n",
    "    \"noncommittal\": 0\n",
    "}\n",
    "\n",
    "Example 2\n",
    "Input: {\n",
    "    \"response\": \"I don't know about the  groundbreaking feature of the smartphone invented in 2023 as am unaware of information beyond 2022. \"\n",
    "}\n",
    "Output: {\n",
    "    \"question\": \"What was the groundbreaking feature of the smartphone invented in 2023?\",\n",
    "    \"noncommittal\": 1\n",
    "}\n",
    "-----------------------------\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc2_'></a>[Загрузка датасета с google.sheets](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pres_name</th>\n",
       "      <th>question</th>\n",
       "      <th>page</th>\n",
       "      <th>content</th>\n",
       "      <th>comment</th>\n",
       "      <th>MinScorer</th>\n",
       "      <th>Hyperbolic Scorer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Kept_Подвижной состав РФ_2024 (20 стр)</td>\n",
       "      <td>Развитие парка цистерн</td>\n",
       "      <td>14</td>\n",
       "      <td>text</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ЯиП_Энергетический_переход_Вызовы_и_возможност...</td>\n",
       "      <td>В какой презентации говорили о снижении доли и...</td>\n",
       "      <td>14</td>\n",
       "      <td>text</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>SP_Навигатор_по_мерам_гос_поддержки_2024_74_стр</td>\n",
       "      <td>Презентация в которой рассматривались субсидии...</td>\n",
       "      <td>23</td>\n",
       "      <td>text</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PASS</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>AXES_х_Понимаю_Исследование_практик_благополуч...</td>\n",
       "      <td>Благополучие</td>\n",
       "      <td></td>\n",
       "      <td>general</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FAIL</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3. Тенденции рынка труда 2024</td>\n",
       "      <td>Презентация про управление персоналом</td>\n",
       "      <td>14</td>\n",
       "      <td>text</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            pres_name  \\\n",
       "7              Kept_Подвижной состав РФ_2024 (20 стр)   \n",
       "4   ЯиП_Энергетический_переход_Вызовы_и_возможност...   \n",
       "23    SP_Навигатор_по_мерам_гос_поддержки_2024_74_стр   \n",
       "14  AXES_х_Понимаю_Исследование_практик_благополуч...   \n",
       "17                      3. Тенденции рынка труда 2024   \n",
       "\n",
       "                                             question page  content comment  \\\n",
       "7                              Развитие парка цистерн   14     text     NaN   \n",
       "4   В какой презентации говорили о снижении доли и...   14     text     NaN   \n",
       "23  Презентация в которой рассматривались субсидии...   23     text     NaN   \n",
       "14                                       Благополучие       general     NaN   \n",
       "17              Презентация про управление персоналом   14     text     NaN   \n",
       "\n",
       "   MinScorer Hyperbolic Scorer  \n",
       "7        NaN               NaN  \n",
       "4        NaN               NaN  \n",
       "23      PASS              PASS  \n",
       "14      FAIL              PASS  \n",
       "17       NaN               NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sheet_id = os.environ[\"BENCHMARK_SPREADSHEET_ID\"]\n",
    "\n",
    "csv_load_url = f\"https://docs.google.com/spreadsheets/d/{sheet_id}/export?format=csv\"\n",
    "df = pd.read_csv(csv_load_url)\n",
    "df.fillna(dict(page=\"\"), inplace=True)\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"pres_name\"].str.contains(\"pdf\").sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc3_'></a>[Инициализация Retrieval](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/groot/Desktop/projects/global/PresRAG/presentation-rag/src/config/model_setup.py:36: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  return ChatOpenAI(\n"
     ]
    }
   ],
   "source": [
    "config = Config()\n",
    "llm = config.model_config.load_vsegpt(model=\"\")\n",
    "\n",
    "collection_name = \"pres0\"\n",
    "embeddings = config.embedding_config.load_vsegpt()\n",
    "storage = ChromaSlideStore(\"pres0\", embedding_model=embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'answer': 'pres_name: 4.Обзор уязвимостей и техник защиты для LLM_Евгений '\n",
      "           'Кокуйкин_вер.3\\n'\n",
      "           '\\n'\n",
      "           '---\\n'\n",
      "           '\\n'\n",
      "           'Slide 14:\\n'\n",
      "           '\\n'\n",
      "           '\\n'\n",
      "           'Text Content:\\n'\n",
      "           '\\n'\n",
      "           'Заголовок: \"Grok Илонa Маска без цензуры\"\\n'\n",
      "           '\\n'\n",
      "           'Текст твита:\\n'\n",
      "           'Max Zeff @ZeффMax\\n'\n",
      "           '\"Can you generate an image of Donald Trump smoking a joint on the '\n",
      "           'Joe Rogan show\"\\n'\n",
      "           '\\n'\n",
      "           'Стилизация текста: заголовок выполнен крупным шрифтом синего '\n",
      "           'цвета, что привлекает внимание к основной теме слайда. Текст твита '\n",
      "           'представлен в стандартном шрифте, что подчеркивает его '\n",
      "           'второстепенное значение.\\n'\n",
      "           '\\n'\n",
      "           '\\n'\n",
      "           'Visual Content:\\n'\n",
      "           '\\n'\n",
      "           'На слайде изображение Дональда Трампа, который курит, находится '\n",
      "           'справа. Он одет в темный костюм и наушники, что создает '\n",
      "           'впечатление, что он участвует в разговоре. Слева расположен текст '\n",
      "           'твита, который также содержит имя пользователя и его никнейм. Фон '\n",
      "           'слайда черный, что делает текст и изображение более заметными.\\n'\n",
      "           '\\n'\n",
      "           '\\n'\n",
      "           'Topic Overview:\\n'\n",
      "           '\\n'\n",
      "           'Тема: Обсуждение Илонa Маска и его влияния на общественное '\n",
      "           'мнение.\\n'\n",
      "           'Цель: Показать провокационный твит о Дональде Трампе.\\n'\n",
      "           'Ключевая информация: Визуализация взаимодействия между известными '\n",
      "           'личностями и их влиянием на медиа.\\n'\n",
      "           '\\n'\n",
      "           '\\n'\n",
      "           'Conclusions And Insights:\\n'\n",
      "           '\\n'\n",
      "           'Основное сообщение: Влияние социальных медиа на восприятие '\n",
      "           'публичных фигур. Твит поднимает вопросы о свободе слова и цензуре '\n",
      "           'в контексте известных личностей.\\n'\n",
      "           '\\n'\n",
      "           '\\n'\n",
      "           'Layout And Composition:\\n'\n",
      "           '\\n'\n",
      "           'Слайд имеет четкую структуру: заголовок в верхней части, текст '\n",
      "           'твита слева, изображение Трампа справа. Используется контрастный '\n",
      "           'фон для выделения элементов.',\n",
      " 'contexts': ['Slide 15:\\n'\n",
      "              '\\n'\n",
      "              '\\n'\n",
      "              'Text Content:\\n'\n",
      "              '\\n'\n",
      "              'Заголовок: \"У каждой модели свой Safety\"\\n'\n",
      "              '\\n'\n",
      "              'Основной текст: \"Я не могу создать изображение Дональда Трампа, '\n",
      "              'курящего джоинт на шоу Джо Рогана, из-за ограничений на '\n",
      "              'создание таких изображений с реальными публичными личностями. '\n",
      "              'Могу предложить создать обобщенную сцену на ток-шоу без '\n",
      "              'указания реальных лиц. Подойдет?\"\\n'\n",
      "              '\\n'\n",
      "              'Стилизация текста: заголовок выделен крупным шрифтом, что '\n",
      "              'подчеркивает важность темы. Основной текст представлен '\n",
      "              'стандартным шрифтом, что делает его легко читаемым.\\n'\n",
      "              '\\n'\n",
      "              '\\n'\n",
      "              'Visual Content:\\n'\n",
      "              '\\n'\n",
      "              'Слайд имеет минималистичный дизайн. Заголовок расположен в '\n",
      "              'верхней части слайда, занимает центральное место. Основной '\n",
      "              'текст расположен ниже заголовка, выровнен по левому краю. В '\n",
      "              'левом нижнем углу находится логотип мероприятия \"AIConf 2023\", '\n",
      "              'что добавляет элемент брендинга. Фон слайда светлый, что '\n",
      "              'способствует хорошей читаемости текста.\\n'\n",
      "              '\\n'\n",
      "              '\\n'\n",
      "              'Topic Overview:\\n'\n",
      "              '\\n'\n",
      "              'Тема: Ограничения на создание изображений публичных личностей\\n'\n",
      "              'Цель: Обсудить вопросы безопасности и ограничения в контексте '\n",
      "              'генерации изображений\\n'\n",
      "              'Ключевая информация: Упоминание о невозможности создания '\n",
      "              'изображений реальных людей в определенных контекстах.\\n'\n",
      "              '\\n'\n",
      "              '\\n'\n",
      "              'Conclusions And Insights:\\n'\n",
      "              '\\n'\n",
      "              'Основной вывод: Существуют ограничения на создание изображений '\n",
      "              'публичных личностей, что требует поиска альтернативных '\n",
      "              'решений.\\n'\n",
      "              '\\n'\n",
      "              '\\n'\n",
      "              'Layout And Composition:\\n'\n",
      "              '\\n'\n",
      "              'Слайд имеет четкую иерархическую структуру: заголовок вверху, '\n",
      "              'основной текст ниже. Используется достаточно белого '\n",
      "              'пространства для улучшения восприятия информации.',\n",
      "              'Slide 4:\\n'\n",
      "              '\\n'\n",
      "              '\\n'\n",
      "              'Text Content:\\n'\n",
      "              '\\n'\n",
      "              'Заголовок: \"Дипфейк звонит в Ferrari\"\\n'\n",
      "              '\\n'\n",
      "              'Текстовые блоки:\\n'\n",
      "              '1. \"Мошенники выдали себя за директора и хотели убедить '\n",
      "              'подписать документы.\"\\n'\n",
      "              '2. \"Голос имитировал итальянский акцент директора, но '\n",
      "              'топ-менеджер заметил неестественные интонации.\"\\n'\n",
      "              '3. \"Он проверил личность, задав вопрос о книге, которую они '\n",
      "              'обсуждали с директором раньше.\"\\n'\n",
      "              '4. \"Мошенник прекратил общение, и Ferrari начала '\n",
      "              'расследование.\"\\n'\n",
      "              '\\n'\n",
      "              'Стилизация текста: заголовок выделен жирным шрифтом, основной '\n",
      "              'текст представлен в стандартном размере, с использованием '\n",
      "              'эмодзи для визуального акцента.\\n'\n",
      "              '\\n'\n",
      "              '\\n'\n",
      "              'Visual Content:\\n'\n",
      "              '\\n'\n",
      "              'Слайд содержит эмодзи, которые иллюстрируют ключевые моменты:\\n'\n",
      "              '- Эмодзи с маской (мошенники) перед первым пунктом.\\n'\n",
      "              '- Эмодзи с говорящей головой перед вторым пунктом.\\n'\n",
      "              '- Эмодзи вопросительного знака перед третьим пунктом.\\n'\n",
      "              '- Эмодзи лупы перед четвертым пунктом.\\n'\n",
      "              '\\n'\n",
      "              'Логотип \"AIConf 2023\" расположен в правом нижнем углу, а '\n",
      "              'источник информации указан внизу слайда.\\n'\n",
      "              '\\n'\n",
      "              '\\n'\n",
      "              'Topic Overview:\\n'\n",
      "              '\\n'\n",
      "              'Тема: Использование дипфейков в мошенничестве\\n'\n",
      "              'Цель: Показать, как мошенники используют технологии для обмана\\n'\n",
      "              'Ключевая информация: Пример мошенничества с использованием '\n",
      "              'дипфейка в компании Ferrari.\\n'\n",
      "              '\\n'\n",
      "              '\\n'\n",
      "              'Conclusions And Insights:\\n'\n",
      "              '\\n'\n",
      "              'Основные выводы:\\n'\n",
      "              '- Дипфейки могут быть использованы для создания правдоподобных '\n",
      "              'обманов.\\n'\n",
      "              '- Важно проверять личность собеседника, особенно в деловых '\n",
      "              'переговорах.\\n'\n",
      "              '- Компании должны быть готовы к расследованию подобных '\n",
      "              'инцидентов.\\n'\n",
      "              '\\n'\n",
      "              '\\n'\n",
      "              'Layout And Composition:\\n'\n",
      "              '\\n'\n",
      "              'Слайд имеет четкую структуру:\\n'\n",
      "              '- Заголовок в верхней части слайда.\\n'\n",
      "              '- Текстовые блоки расположены по центру, каждый пункт выделен '\n",
      "              'эмодзи.\\n'\n",
      "              '- Логотип и источник информации размещены в нижней части '\n",
      "              'слайда.',\n",
      "              'Slide 7:\\n'\n",
      "              '\\n'\n",
      "              '\\n'\n",
      "              'Text Content:\\n'\n",
      "              '\\n'\n",
      "              'Основной заголовок: \"Дипфейки и в науке тоже\"\\n'\n",
      "              '\\n'\n",
      "              'Текст: \"Группа учёных из Оксфорда и Sakana.ai создала фреймворк '\n",
      "              'AI Scientist, генерирующий очень реалистичные научные статьи в '\n",
      "              'формате популярных конференций\" 💩\\n'\n",
      "              '\\n'\n",
      "              'Текст: \"LLM-detetvAlve детектирует научные статьи, написанные '\n",
      "              'ИИ, с точностью 97.5% 👍\"\\n'\n",
      "              '\\n'\n",
      "              'Список:\\n'\n",
      "              '— авторский человеческий\\n'\n",
      "              '— сгенерированный машиной\\n'\n",
      "              '— авторский, но с LLM-постобработкой\\n'\n",
      "              '— сгенерированный и с LLM-постобработкой\\n'\n",
      "              '\\n'\n",
      "              'Стилизация текста: заголовок выделен жирным шрифтом, '\n",
      "              'использован крупный размер шрифта для акцента на заголовке и '\n",
      "              'ключевых фразах.\\n'\n",
      "              '\\n'\n",
      "              '\\n'\n",
      "              'Visual Content:\\n'\n",
      "              '\\n'\n",
      "              'Слайд имеет минималистичный дизайн с белым фоном. В правом '\n",
      "              'нижнем углу расположен логотип конференции AIConf 2023. Номер '\n",
      "              'слайда (8) находится в верхнем правом углу. Эмодзи 💩 и 👍 '\n",
      "              'добавляют визуальный интерес и подчеркивают неформальный стиль '\n",
      "              'представления информации.\\n'\n",
      "              '\\n'\n",
      "              '\\n'\n",
      "              'Topic Overview:\\n'\n",
      "              '\\n'\n",
      "              'Тема: Влияние дипфейков на научные публикации\\n'\n",
      "              'Цель: Показать, как технологии ИИ могут генерировать и '\n",
      "              'детектировать научные статьи\\n'\n",
      "              'Ключевая информация: Презентация фреймворка AI Scientist и его '\n",
      "              'возможностей.\\n'\n",
      "              '\\n'\n",
      "              '\\n'\n",
      "              'Conclusions And Insights:\\n'\n",
      "              '\\n'\n",
      "              'Основные выводы:\\n'\n",
      "              '- AI Scientist генерирует реалистичные научные статьи.\\n'\n",
      "              '- LLM-detetvAlve показывает высокую точность в детекции статей, '\n",
      "              'написанных ИИ.\\n'\n",
      "              '- Важно различать авторские и сгенерированные материалы.\\n'\n",
      "              '\\n'\n",
      "              '\\n'\n",
      "              'Layout And Composition:\\n'\n",
      "              '\\n'\n",
      "              'Слайд имеет четкую иерархию: заголовок вверху, основной текст и '\n",
      "              'список ниже. Логотип и номер слайда расположены в углах, что '\n",
      "              'создает сбалансированное восприятие.'],\n",
      " 'pres_info': {'pages': [14, 15, 4, 7],\n",
      "               'pres_name': '4.Обзор уязвимостей и техник защиты для '\n",
      "                            'LLM_Евгений Кокуйкин_вер.3'}}\n"
     ]
    }
   ],
   "source": [
    "from src.rag.score import ExponentialScorer, HyperbolicScorer, MinScorer, ExponentialWeightedScorer, HyperbolicWeightedScorer\n",
    "from src.rag import SlideRetriever\n",
    "from pprint import pprint\n",
    "\n",
    "question = \"Слайд с Трампом\"\n",
    "question = \"Презентация с мемом про Трампа\"\n",
    "\n",
    "scorer = ExponentialScorer()\n",
    "retriever = SlideRetriever(storage=storage, scorer=scorer)\n",
    "\n",
    "out = retriever.retrieve(question)\n",
    "pprint(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Убедимся, что vsegpt и openai дают одинаковые эмбеддинги"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.embedding_config.load_vsegpt()\n",
    "oai_emb = config.embedding_config.load_openai()\n",
    "vgpt_emb = config.embedding_config.load_vsegpt()\n",
    "oai_emb.embed_query(question) == vgpt_emb.embed_query(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# from ragas.dataset_schema import SingleTurnSample\n",
    "from ragas.metrics import Faithfulness, LLMContextRecall\n",
    "from ragas import SingleTurnSample, EvaluationDataset\n",
    "from ragas.llms.base import LangchainLLMWrapper\n",
    "\n",
    "\n",
    "llm = config.model_config.load_vsegpt(model=\"openai/gpt-4o-mini\")\n",
    "llm = LangchainLLMWrapper(llm)\n",
    "\n",
    "question = \"When was the first super bowl?\"\n",
    "contexts = [\"The First AFL–NFL World Championship Game was an American football game played on January 15, 1967, at the Los Angeles Memorial Coliseum in Los Angeles.\"]\n",
    "answer = \"The first superbowl was held on Jan 15, 1967\"\n",
    "\n",
    "\n",
    "sample = SingleTurnSample(\n",
    "        user_input=question,\n",
    "        response=answer,\n",
    "        # reference=\"on January 15, 1967\",\n",
    "        retrieved_contexts=contexts\n",
    "    )\n",
    "\n",
    "dataset = EvaluationDataset(samples=[sample])\n",
    "\n",
    "metrics = [Faithfulness(llm=llm)]\n",
    "for m in metrics:\n",
    "    m.__setattr__(\"llm\", llm)\n",
    "    m.__setattr__(\"embeddings\", embeddings)\n",
    "\n",
    "from ragas.integrations.langchain import EvaluatorChain\n",
    "out = metrics[0].single_turn_score(sample)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Через датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76e225d232ad47e08d868dc14608fbf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'faithfulness': 1.0000}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ragas import evaluate\n",
    "out = evaluate(dataset=dataset, llm=llm, metrics=metrics)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using existing dataset:  RAGAS_5\n"
     ]
    }
   ],
   "source": [
    "from langsmith import Client\n",
    "from langsmith.utils import LangSmithError\n",
    "\n",
    "# Create dataset\n",
    "client = Client()\n",
    "dataset_name = \"RAGAS_5\"\n",
    "\n",
    "try:\n",
    "    # check if dataset exists\n",
    "    dataset = client.read_dataset(dataset_name=dataset_name)\n",
    "    print(\"using existing dataset: \", dataset.name)\n",
    "except LangSmithError:\n",
    "    # if not create a new one with the generated query examples\n",
    "    dataset = client.create_dataset(dataset_name=dataset_name)\n",
    "    df_5 = df.sample(5)\n",
    "    for i, row in df_5.iterrows():\n",
    "        client.create_example(\n",
    "            inputs=dict(question=row[\"question\"]),\n",
    "            outputs=dict(\n",
    "                ground_truth=\"\",\n",
    "                pres_name=row[\"pres_name\"],\n",
    "                pages=[int(x) if x else -1 for x in row[\"page\"].split(\",\")]\n",
    "            ),\n",
    "            dataset_id=dataset.id,\n",
    "        )\n",
    "\n",
    "    print(\"Created a new dataset: \", dataset.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc4_'></a>[Правила для оценки (evaluators)](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith.evaluation import EvaluationResult, run_evaluator\n",
    "from ragas import SingleTurnSample, EvaluationDataset\n",
    "from ragas.llms.base import LangchainLLMWrapper\n",
    "\n",
    "@run_evaluator\n",
    "def presentation_match(run, example) -> EvaluationResult:\n",
    "    prediction = run.outputs[\"pres_info\"][\"pres_name\"]\n",
    "    match = int(prediction == example.outputs[\"pres_name\"])\n",
    "    return EvaluationResult(key=\"presentation_match\", score=match)\n",
    "\n",
    "\n",
    "def ragas_evaluator(metric):\n",
    "    @run_evaluator\n",
    "    async def evaluate(run, example) -> EvaluationResult:\n",
    "        sample = SingleTurnSample(\n",
    "            user_input=example.inputs[\"question\"],\n",
    "            response=run.outputs[\"answer\"],\n",
    "            # reference=\"\",\n",
    "            retrieved_contexts=run.outputs[\"contexts\"],\n",
    "        )\n",
    "        score = await metric.single_turn_ascore(sample)\n",
    "\n",
    "        return EvaluationResult(key=metric.name, score=score)\n",
    "    return evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc5_'></a>[Запуск тестов](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import evaluate\n",
    "from ragas.metrics import (\n",
    "    AnswerCorrectness, AnswerRelevancy,\n",
    "    ContextPrecision, ContextRecall,\n",
    "    Faithfulness,\n",
    ")\n",
    "from ragas.llms.base import LangchainLLMWrapper\n",
    "\n",
    "# Jupyter async hack\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# make eval chains\n",
    "llm = config.model_config.load_vsegpt(model=\"openai/gpt-4o-mini\")\n",
    "llm = LangchainLLMWrapper(llm)\n",
    "\n",
    "# Setup metrics\n",
    "eval_chains = {}\n",
    "eval_chains[\"presentation_match\"] = presentation_match\n",
    "\n",
    "metrics = [Faithfulness]\n",
    "for m in metrics:\n",
    "    metric_with_llm = m(llm=llm)\n",
    "    evaluator = ragas_evaluator(metric_with_llm)\n",
    "    eval_chains.update({m.name: evaluator})\n",
    "\n",
    "eval_chains_list = list(eval_chains.values())\n",
    "\n",
    "# Setup scorers for RAG reranking\n",
    "# scorers = [MinScorer(), HyperbolicScorer(), ExponentialScorer(), HyperbolicWeightedScorer(), ExponentialWeightedScorer()]\n",
    "scorers = [MinScorer(), HyperbolicScorer()]\n",
    "\n",
    "# Run evaluation. Results will be available in Langsmith\n",
    "for scorer in scorers:\n",
    "    retriever = SlideRetriever(storage=storage, scorer=scorer)\n",
    "    out = evaluate(\n",
    "        retriever,\n",
    "        experiment_prefix=f\"{retriever.scorer.id}\",\n",
    "        data=dataset_name,\n",
    "        evaluators=eval_chains_list,\n",
    "        metadata=dict(\n",
    "            scorer=retriever.scorer.id\n",
    "        ),\n",
    "        max_concurrency=2,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**See the results in Langsmith**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "**Deepeval (not finished)**\n",
    "\n",
    "Эту часть я не доделал.\n",
    "\n",
    "Deepeval - фреймворк для оценки моделей. Там есть метрики RAGAS. Можно оценивать через него"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepeval import evaluate\n",
    "from deepeval.metrics.ragas import RagasMetric\n",
    "from deepeval.test_case import LLMTestCase\n",
    "from deepeval.metrics.ragas import RAGASFaithfulnessMetric\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from deepeval.models.base_model import DeepEvalBaseLLM\n",
    "import json\n",
    "\n",
    "class LangchainModelEval(DeepEvalBaseLLM):\n",
    "    def __init__(self, llm):\n",
    "        self.llm = llm\n",
    "\n",
    "    def load_model(self, *args, **kwargs):\n",
    "        return self.llm\n",
    "\n",
    "    def generate(self, prompt: str) -> str:\n",
    "        chain = self.llm | StrOutputParser() # | json.loads\n",
    "        out = chain.invoke(prompt)\n",
    "        return out\n",
    "\n",
    "    async def a_generate(self, prompt: str, *args, **kwargs) -> str:\n",
    "        schema = kwargs.get(\"schema\")\n",
    "        out = self.generate(prompt)\n",
    "        out = out if schema is None else schema(out)\n",
    "        return out\n",
    "\n",
    "    def get_model_name(self):\n",
    "        llm_class = self.llm.__class__.__name__\n",
    "        model_string = self.llm.model_name if hasattr(self.llm, \"model_name\") else self.llm.model\n",
    "        model_string = model_string.replace(\"/\", \"-\")\n",
    "        return f\"{llm_class}-{model_string}\"\n",
    "\n",
    "\n",
    "question = \"When was the first super bowl?\"\n",
    "contexts = [\"The First AFL–NFL World Championship Game was an American football game played on January 15, 1967, at the Los Angeles Memorial Coliseum in Los Angeles.\"]\n",
    "answer = \"The first superbowl was held on Jan 15, 1967\"\n",
    "\n",
    "llm = config.model_config.load_vsegpt(model=\"openai/gpt-4o-mini\")\n",
    "metrics = [RagasMetric(threshold=0.5, model=llm)]\n",
    "metric = RAGASFaithfulnessMetric(model=llm)\n",
    "\n",
    "test_case = LLMTestCase(\n",
    "    input=question,\n",
    "    actual_output=answer,\n",
    "    retrieval_context=contexts\n",
    ")\n",
    "\n",
    "metric.measure(test_case)\n",
    "print(metric.score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Dataset(name='RAG_test_25', description=None, data_type=<DataType.kv: 'kv'>, id=UUID('dc15e6f2-dea2-48f5-a9f1-76cbe7ebd172'), created_at=datetime.datetime(2024, 12, 1, 12, 25, 6, 335839, tzinfo=datetime.timezone.utc), modified_at=datetime.datetime(2024, 12, 1, 12, 25, 6, 335839, tzinfo=datetime.timezone.utc), example_count=25, session_count=8, last_session_start_time=datetime.datetime(2024, 12, 1, 14, 33, 43, 45139), inputs_schema=None, outputs_schema=None),\n",
       " Dataset(name='Pragmatics_12', description=None, data_type=<DataType.kv: 'kv'>, id=UUID('9f113efd-afb3-4d0d-a21c-e64c30add6c3'), created_at=datetime.datetime(2024, 4, 4, 11, 10, 16, 777543, tzinfo=datetime.timezone.utc), modified_at=datetime.datetime(2024, 4, 4, 11, 10, 16, 777543, tzinfo=datetime.timezone.utc), example_count=11, session_count=1, last_session_start_time=datetime.datetime(2024, 4, 4, 11, 10, 38, 417340), inputs_schema=None, outputs_schema=None),\n",
       " Dataset(name='Chegeka_100', description=None, data_type=<DataType.kv: 'kv'>, id=UUID('6aa28b67-b587-4aa6-b338-a872dd3fffe1'), created_at=datetime.datetime(2024, 3, 21, 17, 32, 55, 619886, tzinfo=datetime.timezone.utc), modified_at=datetime.datetime(2024, 3, 21, 17, 32, 55, 619886, tzinfo=datetime.timezone.utc), example_count=100, session_count=6, last_session_start_time=datetime.datetime(2024, 3, 26, 10, 26, 42, 402644), inputs_schema=None, outputs_schema=None),\n",
       " Dataset(name='Chegeka', description=None, data_type=<DataType.kv: 'kv'>, id=UUID('c41320a9-8e00-4886-9aed-6c437d8d8fc5'), created_at=datetime.datetime(2024, 3, 21, 12, 34, 54, 713105, tzinfo=datetime.timezone.utc), modified_at=datetime.datetime(2024, 3, 21, 12, 34, 54, 713105, tzinfo=datetime.timezone.utc), example_count=5, session_count=20, last_session_start_time=datetime.datetime(2024, 3, 26, 10, 15, 3, 538303), inputs_schema=None, outputs_schema=None),\n",
       " Dataset(name='RAG_test_25_groundtruth-None', description=None, data_type=<DataType.kv: 'kv'>, id=UUID('52b90d35-83ac-4467-8e63-472323c5fb2e'), created_at=datetime.datetime(2024, 12, 1, 15, 3, 4, 684918, tzinfo=datetime.timezone.utc), modified_at=datetime.datetime(2024, 12, 1, 15, 3, 4, 684918, tzinfo=datetime.timezone.utc), example_count=0, session_count=0, last_session_start_time=None, inputs_schema=None, outputs_schema=None)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(client.list_projects())\n",
    "list(client.list_datasets())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
