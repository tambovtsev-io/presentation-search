{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys, os\n",
    "sys.path.append(os.path.abspath(\"../../\"))\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.config import Config, load_spreadsheet\n",
    "from src.rag import (\n",
    "    ChromaSlideStore,\n",
    "    HyperbolicScorer,\n",
    "    MinScorer,\n",
    "    PresentationRetriever,\n",
    "    ScorerTypes,\n",
    ")\n",
    "from src.eval.eval_mlflow import EvaluationConfig, RAGEvaluator\n",
    "\n",
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mlflow setup logging\n",
    "mlflow.langchain.autolog()\n",
    "\n",
    "# Setup components\n",
    "project_config = Config()\n",
    "llm = project_config.model_config.load_vsegpt(model=\"openai/gpt-4o-mini\")\n",
    "embeddings = project_config.embedding_config.load_vsegpt()\n",
    "\n",
    "storage = ChromaSlideStore(collection_name=\"pres0\", embedding_model=embeddings)\n",
    "\n",
    "db_path = project_config.navigator.processed / \"eval\" / \"mlruns.db\"\n",
    "eval_config = EvaluationConfig(\n",
    "    experiment_name=\"PresRetrieve_mlflow\",\n",
    "    metrics=[\"presentation_match\", \"page_match\"],\n",
    "    scorers=[MinScorer(), HyperbolicScorer()],\n",
    "    tracking_uri=f\"sqlite:////{db_path}\",\n",
    ")\n",
    "\n",
    "evaluator = RAGEvaluator(\n",
    "    storage=storage,\n",
    "    config=eval_config,\n",
    "    # llm=llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pres_name</th>\n",
       "      <th>question</th>\n",
       "      <th>page</th>\n",
       "      <th>content</th>\n",
       "      <th>comment</th>\n",
       "      <th>MinScorer</th>\n",
       "      <th>Hyperbolic Scorer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Kept_Подвижной состав РФ_2024 (20 стр)</td>\n",
       "      <td>Развитие парка цистерн</td>\n",
       "      <td>14</td>\n",
       "      <td>text</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>SP_Навигатор_по_мерам_гос_поддержки_2024_74_стр</td>\n",
       "      <td>Презентация в которой рассматривались субсидии...</td>\n",
       "      <td>23</td>\n",
       "      <td>text</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PASS</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Kept_Подвижной состав РФ_2024 (20 стр)</td>\n",
       "      <td>Про что рассказывал Сергей Казачков?</td>\n",
       "      <td>2,20</td>\n",
       "      <td>text</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PASS</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>4.Эволюция отбора кандидатов в системе товарны...</td>\n",
       "      <td>Презентация про маркетплейсы</td>\n",
       "      <td></td>\n",
       "      <td>general</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FAIL</td>\n",
       "      <td>FAIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ЯиП_Энергетический_переход_Вызовы_и_возможност...</td>\n",
       "      <td>В какой презентации говорили о снижении доли и...</td>\n",
       "      <td>14</td>\n",
       "      <td>text</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            pres_name  \\\n",
       "7              Kept_Подвижной состав РФ_2024 (20 стр)   \n",
       "23    SP_Навигатор_по_мерам_гос_поддержки_2024_74_стр   \n",
       "8              Kept_Подвижной состав РФ_2024 (20 стр)   \n",
       "21  4.Эволюция отбора кандидатов в системе товарны...   \n",
       "4   ЯиП_Энергетический_переход_Вызовы_и_возможност...   \n",
       "\n",
       "                                             question  page  content comment  \\\n",
       "7                              Развитие парка цистерн    14     text     NaN   \n",
       "23  Презентация в которой рассматривались субсидии...    23     text     NaN   \n",
       "8                Про что рассказывал Сергей Казачков?  2,20     text     NaN   \n",
       "21                       Презентация про маркетплейсы        general     NaN   \n",
       "4   В какой презентации говорили о снижении доли и...    14     text     NaN   \n",
       "\n",
       "   MinScorer Hyperbolic Scorer  \n",
       "7        NaN               NaN  \n",
       "23      PASS              PASS  \n",
       "8       PASS              PASS  \n",
       "21      FAIL              FAIL  \n",
       "4        NaN               NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "MlflowException",
     "evalue": "Invalid artifact path: '/home/groot/Desktop/projects/global/PresRAG/presentation-rag/data/processed/eval/detailed_results.csv'. Names may be treated as files in certain cases, and must not resolve to other names when treated as such. This name would resolve to '/home/groot/Desktop/projects/global/PresRAG/presentation-rag/data/processed/eval/detailed_results.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMlflowException\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m display(df_eval)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Run evaluation\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[43mevaluator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_evaluation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_eval\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/projects/global/PresRAG/presentation-rag/src/eval/eval_mlflow.py:291\u001b[0m, in \u001b[0;36mRAGEvaluator.run_evaluation\u001b[0;34m(self, questions_df)\u001b[0m\n\u001b[1;32m    289\u001b[0m     results_df\u001b[38;5;241m.\u001b[39mto_csv(f\u001b[38;5;241m.\u001b[39mname, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    290\u001b[0m     fpath \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(Config()\u001b[38;5;241m.\u001b[39mnavigator\u001b[38;5;241m.\u001b[39meval \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdetailed_results.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 291\u001b[0m     \u001b[43mmlflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_artifact\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;66;03m# Log average metrics\u001b[39;00m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, values \u001b[38;5;129;01min\u001b[39;00m metric_values\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[0;32m~/Desktop/projects/global/PresRAG/presentation-rag/.venv/lib/python3.10/site-packages/mlflow/tracking/fluent.py:1172\u001b[0m, in \u001b[0;36mlog_artifact\u001b[0;34m(local_path, artifact_path, run_id)\u001b[0m\n\u001b[1;32m   1142\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1143\u001b[0m \u001b[38;5;124;03mLog a local file or directory as an artifact of the currently active run. If no run is\u001b[39;00m\n\u001b[1;32m   1144\u001b[0m \u001b[38;5;124;03mactive, this method will create a new active run.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1169\u001b[0m \u001b[38;5;124;03m            mlflow.log_artifact(path)\u001b[39;00m\n\u001b[1;32m   1170\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1171\u001b[0m run_id \u001b[38;5;241m=\u001b[39m run_id \u001b[38;5;129;01mor\u001b[39;00m _get_or_start_run()\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mrun_id\n\u001b[0;32m-> 1172\u001b[0m \u001b[43mMlflowClient\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_artifact\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martifact_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/projects/global/PresRAG/presentation-rag/.venv/lib/python3.10/site-packages/mlflow/tracking/client.py:1928\u001b[0m, in \u001b[0;36mMlflowClient.log_artifact\u001b[0;34m(self, run_id, local_path, artifact_path)\u001b[0m\n\u001b[1;32m   1924\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_id\u001b[38;5;241m.\u001b[39mstartswith(TRACE_REQUEST_ID_PREFIX):\n\u001b[1;32m   1925\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\n\u001b[1;32m   1926\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid run id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrun_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. `log_artifact` run id must map to a valid run.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1927\u001b[0m     )\n\u001b[0;32m-> 1928\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tracking_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_artifact\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martifact_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/projects/global/PresRAG/presentation-rag/.venv/lib/python3.10/site-packages/mlflow/tracking/_tracking_service/client.py:842\u001b[0m, in \u001b[0;36mTrackingServiceClient.log_artifact\u001b[0;34m(self, run_id, local_path, artifact_path)\u001b[0m\n\u001b[1;32m    840\u001b[0m     artifact_repo\u001b[38;5;241m.\u001b[39mlog_artifacts(local_path, path_name)\n\u001b[1;32m    841\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 842\u001b[0m     \u001b[43martifact_repo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_artifact\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocal_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martifact_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/projects/global/PresRAG/presentation-rag/.venv/lib/python3.10/site-packages/mlflow/store/artifact/local_artifact_repo.py:33\u001b[0m, in \u001b[0;36mLocalArtifactRepository.log_artifact\u001b[0;34m(self, local_file, artifact_path)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlog_artifact\u001b[39m(\u001b[38;5;28mself\u001b[39m, local_file, artifact_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m---> 33\u001b[0m     \u001b[43mverify_artifact_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43martifact_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;66;03m# NOTE: The artifact_path is expected to be in posix format.\u001b[39;00m\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;66;03m# Posix paths work fine on windows but just in case we normalize it here.\u001b[39;00m\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artifact_path:\n",
      "File \u001b[0;32m~/Desktop/projects/global/PresRAG/presentation-rag/.venv/lib/python3.10/site-packages/mlflow/store/artifact/artifact_repo.py:449\u001b[0m, in \u001b[0;36mverify_artifact_path\u001b[0;34m(artifact_path)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mverify_artifact_path\u001b[39m(artifact_path):\n\u001b[1;32m    448\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artifact_path \u001b[38;5;129;01mand\u001b[39;00m path_not_unique(artifact_path):\n\u001b[0;32m--> 449\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\n\u001b[1;32m    450\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid artifact path: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00martifact_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbad_path_message(artifact_path)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    451\u001b[0m         )\n",
      "\u001b[0;31mMlflowException\u001b[0m: Invalid artifact path: '/home/groot/Desktop/projects/global/PresRAG/presentation-rag/data/processed/eval/detailed_results.csv'. Names may be treated as files in certain cases, and must not resolve to other names when treated as such. This name would resolve to '/home/groot/Desktop/projects/global/PresRAG/presentation-rag/data/processed/eval/detailed_results.csv'"
     ]
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "# Load questions\n",
    "sheet_id = os.environ[\"BENCHMARK_SPREADSHEET_ID\"]\n",
    "df = evaluator.load_questions_from_sheet(sheet_id)\n",
    "\n",
    "df_eval = df.sample(5)\n",
    "display(df_eval)\n",
    "\n",
    "# Run evaluation\n",
    "evaluator.run_evaluation(df_eval)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
